# take the name of the file and the summary ratio from the user

echo "Please input the name of the text file and summary ratio"
read nameFile
read ratio


#echo $nameFile
#echo $ratio   
> "summry.txt"
value=`cat $nameFile`

echo $value



# to tokenize at the punctuation marks
IFS=['!','.','?']
for word in $value
do 
# remove the stop words and convert the upper case letters to lower case and remove #duplicate words
word=$(echo $word | sed -E 's/(I |a |an |as |at |the |by |in |for |of |on |that )//gI' | tr '[A-Z]' '[a-z]'  |tr ' ' '\n'| uniq |tr '\n ' ' ' | sed 's/^[ \t]*//;s/[ \t]*$//')
echo "$word">>"temp.txt"
done
mv "temp.txt" "$nameFile"

count=`wc -l <"$nameFile"`
#echo $count




sum=0
END=$count
for ((i=1;i<=END;i++)); do
    linei=`sed -n "$i"p "$nameFile" `
    sum=0
    
    for ((j=1;j<=END;j++)); do
    if(($i==$j))
    then
    continue
    fi
    linej=`sed -n "$j"p "$nameFile" `
    
    word=`echo $linei $linej`
    # to calculate the union between two sentences
    union=`echo "$word"| tr ' ' '\n' | sort | uniq | wc -l`
    # to calculate the intersection between two sentences 
    intersection=`echo "$word" |tr ' ' '\n'| sort |uniq -d | wc -l`
    # to calculate similarity between sentences and centrality
    sim=`echo "scale=2; $intersection / $union" | bc -l`
    sum=`echo "$sum + $sim" | bc -l` 
    
    res=`echo "$sum" | bc -l`
    done
    
echo "$res"  $linei >> "summry.txt"
done


# sort according to centrality
echo all sentences with their score:
sort -k1,1nr -k2,2 "summry.txt"
sort -k1,1nr -k2,2 "summry.txt" > "temp1.txt"

#mv "temp1.txt" "summry.txt"
value1=`cat "temp1.txt"`


#select top ranked sentences based on the summary ratio
x=`echo "scale=2;$ratio*$count" | bc -l`
r=${x/.*}
> "summry.txt"

n=1
while (($r>=n)); do
# reading each line
read line
line="${line:4}"
echo $line >> "summry.txt"
n=$((n+1))
done < "temp1.txt"


